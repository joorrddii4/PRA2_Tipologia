---
title: 'Práctica 2: Limpieza y validación de los datos'
author: "Tania Piñeiro y Jordi Sánchez"
date: "09/05/2021"
output: 
  pdf_document:
    toc: yes
    toc_depth: 2
    fig_caption: yes
---

```{r,eval=TRUE,echo=FALSE, include = FALSE}
library(dplyr)
library(stringr)
library(lubridate)
library(psych)
library(ggplot2)
library(kableExtra)
```

# 1. Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?

El dataset seleccionado es el dataset "Titanic" de Kaggle. Ese conjunto de datos contiene datos sobre los pasajeros de este transantlántico como su edad, género, la clase en la que viajaba y también incluye información sobre si sobrevivió al fatal accidente.

Como es bien conocido, el 15 de abril de 1912, el transatlántico de pasajeros más grande jamás construido chocó con un iceberg durante su viaje inaugural. Cuando el Titanic se hundió, mató a 1502 de los 2224 pasajeros y tripulación. Una de las razones por las que el naufragio resultó en tal pérdida de vidas fue que no había suficientes botes salvavidas para los pasajeros y la tripulación. Aunque hubo algún elemento de suerte involucrado en sobrevivir al hundimiento, algunos grupos de personas tenían más probabilidades de sobrevivir que otros.

El análisis de este dataset es importante porque puede ofrecer información sobre si hubo diferencias en la supervivencia de los pasajeros en función de sus características como por ejemplo ¿Hubo una mayor probabilidad de fallecidos entre los pasajeros de las clases más bajas? Los resultados nos permitirán obtener conclusiones valiosas sobre el incidente.

Precisamente éste es el problema que pretende resolver el análisis de este dataset, obtener respuestas sobre las características de los pasajeros con mayores posibilidades de sobrevivir.

En primer lugar, vamos a cargar el dataset y analizar de cuantas variables y registros disponemos para abordar este análisis. Se va a cargar el conjunto "train" de entrenamiento disponible en Kaggle.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Cargamos el juego de datos
ds<- read.csv(file='train.csv',header=T,dec='.', sep=",")
ds_test<- read.csv(file='test.csv',header=T,dec='.', sep=",")
# Verificamos la estructura del conjunto de datos
str(ds)
```

Se observa que se trata de una base de datos con 891 observaciones y 12 variables en las que se recogen algunas características de los pasajeros. Entre las variables hay 7 variables numéricas y 5 categóricas. A continuación se describen las variables:

* PassengerId (tipo int): código de identificación del pasajero
* Survived (tipo int): informa si el pasajero murió o sobrevivió en el accidente(0 = No, 1 = Si)
* Pclass (tipo int): hace referencia a la clase en la que viajaban los pasajeros (1 = primera clase, 2 = segunda clase...)
* Name (tipo char): nombre del pasajero
* Sex (tipo char): sexo del pasajero
* Age (tipo int): edad del pasajero
* SibSp (tipo int): número de familiares (hermanos o esposa) a bordo del Titanic
* Parch (tipo int): número de familiares (padres o hijos) a bordo del Titanic
* Ticket (tipo char): código del ticket del pasajero
* Fare (tipo num): precio del ticket para viajar en el Titanic
* Cabin (tipo char): número del camarote
* Embarked (tipo char): puerto de embarque (C = Cherbourg, Q = Queenstown, S = Southampton)


# 2. Integración y selección de los datos de interés a analizar

En el apartado inicial se ha realizado un análisis preliminar de los datos de los que disponemos en el dataset, obteniendo que tiene un total de 12 columnas y 891 registros. Sin embargo, llegado este punto debemos determinar si realmente necesitamos para nuestro análisis todas esas variables.

Se ha considerado que hay algunas variables que no van a aportar demasiada información al modelo  como son: el código del ticket ("Ticket) y el puerto de embarque ("Embarked"). Sin embargo la variable "Ticket" nos permite conocer cuantas personas han comprado el billete con el mismo ticket y de esta forma, calcular el precio por persona de la variable "Fare", que estará agrupada. La variable "Embarked" se va a excluir del análisis. Además, se ha observado que el número de camarote ("Cabin") está ausente en un gran número de registros, sin embargo, por el momento se va a conservar para analizar si se pueden obtener algunas relaciones entre la ubicación del camarote y el desenlace de los pasajeros.  El nombre de los pasajeros ("Name"), a priori puede parecer poco relevante pero como incluye el título del pasajero ("Mr., Miss...") se van a conservar por si pudiese ser de utilidad.

De esta forma el dataset que vamos a pre-procesar y analizar contará con 11 columnas y 891 registros.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Selección de las variables de interés
ds<-select(ds, "PassengerId","Name","Survived","Pclass", "Sex","Age","SibSp", "Parch", "Fare", "Cabin", "Ticket")
```

Además, para facilitar el trabajo con estos datos vamos a convertir a factores las variables  "Pclass" y "Sex" empleando la función factor. Esto nos facilitará encontrar valores erróneos en futuros pasos y el tratamiento de estas variables para las representaciones gráficas.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#La función factor convierte a factor las variables seleccionadas
ds$Pclass<-factor(ds$Pclass)
ds$Sex<-factor(ds$Sex)
ds$Parch<-factor(ds$Parch)
ds$SibSp<-factor(ds$SibSp)
```

Finalmente, se van a obtener las primeras estadísticas descriptivas del conjunto de datos para empezar a conocer más en profundidad como era la distribución de los pasajeros.

```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(ds)
barplot(prop.table(table(ds$Survived)),col=c("orange","blue"),
        legend.text=c("No sobrevive","Sobrevive"))
```

De los resultados obtenidos se obtienen las siguientes conclusiones:

* De los 891 pasajeros, 549 no sobrevivieron al accidente y 342 sí lo hicieron.
* De los 891 pasajeros, 216 iban en primera clase, 184 en segunda y 491 en tercera.
* De los 891 pasajeros, 314 eran mujeres y 577 hombres.
* La edad de los pasajeros se encuentra entre los 0.42 (posible error) y los 80 años, siendo la edad media 29.7
* Los pasajeros tenían de 0-8 hermanos/esposas a bordo y entre 0-6 hijos/padres.

# 3. Limpieza de los datos

## 3.1. ¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos?

El siguiente paso consistirá en determinar si hay valores nulos y si es así eliminarlos o sustituirlos por otros.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Estadísticas de valores vacíos
colSums(is.na(ds)) %>% kable(caption="Número de NAs por columna") %>% kable_styling(latex_options = "hold_position")
colSums(ds=="", na.rm = TRUE) %>% kable(caption="Número de valores vacíos por columna") %>% kable_styling(latex_options = "hold_position")
```

En las tablas superiores se han obtenido el número de registros con valor "NA" para cada columna y también el número de valores vacíos. En la primera tabla se observa que la única columna se muestra que la única variable que presenta valores ausentes es "Age" con 177 registros NA. 

En la segunda tabla se observa que la única variable que tiene valores vacíos es "Cabin" con 687 registros vacíos. Este es un número muy elevado teniendo en cuenta que nuestro dataset cuenta con 897 registros, significa que el 77% de los registros de esta columna no están disponibles.

En cuanto a la gestión que se va a hacer de estos valores faltantes hemos determinado conservar la variable "Age" ya que consideramos que puede ser muy relevante para el análisis. Se va a realizar una imputación de los valores faltantes, obteniendo la edad media para cada uno de los grupos de títulos de los pasajeros ("Mr, Miss"). Es decir, para una edad faltante de una pasajera tipo "Miss" se le inputará la edad promedio de todas las pasajeras tipo "Miss" del dataset.

Por otra parte, se decide finalmente eliminar la variable "Cabin" ya que se considera que un 77% de datos faltantes es demasiado elevado como para intentar algún tipo de imputación y se podría introducir error.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Se elimina la variable "Cabin"
ds <- ds[,-(10)] 
```

Como se ha comentado la edad se va a estimar en función del título del pasajero. Para ello es necesario, previamente separar el título de la variable "Name" y recogerlo en una variable independiente "Title". Para realizar esta separación se va a emplear una expresión regular, aprovechando que el título aparece tras una coma y un espacio y antes de un punto (Ej: "Braund, Mr. Owen Harris"). A continuación se va a identificar cuántos tipos de títulos hay y su recuento.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Separación del título del pasajero en una nueva columna
ds$Title <- gsub('(.*, )|(\\..*)', '', ds$Name)

table(ds$Title)
```

Se obtiene que hay un total de 17 títulos diferente, aunque la mayoría de ellos son poco frecuentes y solo se encuentran en un par de registros como "Capt", "Major". Estos títulos poco frecuentes se van a agrupar en un único factor, de forma que finalmente habrá 5 niveles: "Miss", "Master", "Mrs", "Mr" y "Other".

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Se agrupan los títulos poco frecuentes
other <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don', 
                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Mlle', 'Ms', 'Mme', 'Lady')
ds$Title[ds$Title %in% other]  <- 'Other'
# Se eliminan los niveles no empleados
ds$Title<-factor(ds$Title)
table(ds$Title)

```
```{r echo=TRUE, message=FALSE, warning=FALSE}
ds_test$Title <- gsub('(.*, )|(\\..*)', '', ds_test$Name)
# Se agrupan los títulos poco frecuentes
ds_test$Title[ds_test$Title %in% other]  <- 'Other'
# Se eliminan los niveles no empleados
ds_test$Title<-factor(ds_test$Title)

```

Ahora observamos que hemos obtenido los cinco grupos de títulos de los pasajeros. Vamos a aprovechar esta información para realizar la inputación de los valores faltantes como el valor promedio de estos grupos.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Se localizan los na de las variables Weight y Height
i_na<-is.na(ds$Age)
dcomplete<-ds[!i_na,]
# Se estima el promedio de edad para cada uno de los grupos 
av_Age_title<-aggregate(x = dcomplete$Age, by = list(dcomplete$Title), FUN = mean) 
# Imputación
ds[which(is.na(ds$Age)&ds$Title=="Master"),"Age"] <- round(av_Age_title[1,2])
ds[which(is.na(ds$Age)&ds$Title=="Miss"),"Age"] <- av_Age_title[2,2]
ds[which(is.na(ds$Age)&ds$Title=="Mr"),"Age"] <- av_Age_title[3,2]
ds[which(is.na(ds$Age)&ds$Title=="Mrs"),"Age"] <- av_Age_title[4,2]
ds[which(is.na(ds$Age)&ds$Title=="Other"),"Age"] <- av_Age_title[5,2]
colSums(is.na(ds))

```
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Se localizan los na de las variables Weight y Height
i_na<-is.na(ds_test$Age)
dcomplete<-ds_test[!i_na,]
# Se estima el promedio de edad para cada uno de los grupos 
av_Age_title<-aggregate(x = dcomplete$Age, by = list(dcomplete$Title), FUN = mean) 
# Imputación
ds_test[which(is.na(ds_test$Age)&ds_test$Title=="Master"),"Age"] <- round(av_Age_title[1,2])
ds_test[which(is.na(ds_test$Age)&ds_test$Title=="Miss"),"Age"] <- av_Age_title[2,2]
ds_test[which(is.na(ds_test$Age)&ds_test$Title=="Mr"),"Age"] <- av_Age_title[3,2]
ds_test[which(is.na(ds_test$Age)&ds_test$Title=="Mrs"),"Age"] <- av_Age_title[4,2]
ds_test[which(is.na(ds_test$Age)&ds_test$Title=="Other"),"Age"] <- av_Age_title[5,2]
colSums(is.na(ds_test))

```

Comprobamos que tras realizar la imputación de valores a la variable "Age" ya no hay ningun registro con valores NA. De esta forma confirmamos que se ha realizado adecuadamente la imputación de valores.
Se podrían haber realizado otros procedimientos para el tratamiento de estos datos faltantes como la eliminación de toda la fila donde se encuentre un registro faltante o la imputación directamente de la edad promedio global. Sin embargo, el número de valores faltantes (177) se consideró demasiado elevado como para eliminar los registros, ya que se perdería gran cantidad de información. Además, la variable age tiene un rango bastante amplio (0.4 - 80 años) de forma que si imputásemos el promedio global de todos los pasajeros probablemente el error que estaríamos introduciendo sería mayor.

## 3.2. Identificación y tratamiento de valores extremos.

Para el tratamiento de valores extremos trabajaremos con las variables "Age", "Fare", "SibSp" y "Parch", ya que son las únicas variables númericas de las que disponemos en el dataset.

Sin embargo, para empezar, verificaremos que entre las variables "Survived", "Pclass", "Sex", "SibSp" y "Parch" que son tipo factor no hay ningún nivel que pueda ser anómalo.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Comprobación de las variables tipo factor
summary(ds[c("Survived", "Pclass", "Sex", "SibSp","Parch")])
```

En los resultados obtenidos se comprueba que no hay ningún valor extremo en estas variables:

__Survived:__ se comprueba que toma valores 0 o 1.
__Pclass:__ toma valores entre 1 y 3.
__Sex:__ se comprueba que hay dos niveles "female" y "male"
__SibSp:__ toma valores entre 0 - 8, siendo los más frecuentes 0 (608 pasajeros) y 1 (209 pasajeros)
__Parch:__ toma valores entre 0 - 6, siendo los más frecuentes 0 (678 pasajeros) y 1 (118 pasajeros)

Vamos ahora a verificar si en las variables "Age" y "Fare" hay valores extremos. Si es así, y se trata de un valor anormalmente alto o bajo, se sustituirá el valor por “NA”, para realizar posteriormente una posible imputación.
Para localizar estos valores extremos se va a emplear la representación boxplot que permite obtener los outliers (valores atípicos) de una determinada variable. Empleando "$out" obtenemos estos valores extremos que son posteriormente sustituidos por NA en las variables originales.

__Age__

```{r,eval=TRUE,echo=TRUE}
# Se representan el boxplot de la variable Age
b1<-boxplot(ds$Age, main="Age")
# Se obtienen las estadísticas
b1$stats
# Se contabilizan los outliers
length(b1$out)
summary(ds[,"Age"])
```

Para la variable Age se obtiene que el valor del bigote inferior es 0.67 y el del bigote superior 57.0. Los extremos de la caja son 21.77 y 35.89, inferior y superior respectivamente, siendo la mediana de la edad de los pasajeros 30.0 años. La interpretación de estos resultados indica que la mitad de los pasajeros a bordo del titanic tenía entre 21.77 y 35.89 años. 
Además se ha obtenido que hay 34 puntos considerados outliers por situarse alejados del resto de datos, 1.5 veces menor o mayor que los extremos de los bigotes. Sin embargo si observamos el rango de la edad de los pasajeros observamos que los valores se encuentran acotados entre 0.42 y 80 años, que son edades razonables. De forma que no se van a eliminar estos outliers, porque forman parte de la diversidad de la muestra. Podrían aplicarse otros procedimientos como la eliminación de las filas con outliers o realizar imputación de estos valores como hicimos en el punto anterior. En este caso se va a realizar la discretización de la variable en grupos de edad, para reducir el ruido de la misma.

```{r,eval=TRUE,echo=TRUE}
# Discretizamos
ds["segmento_edad"] <- cut(ds$Age, breaks = c(0,10,20,30,40,50,60,70,100), labels = c("0-9", "10-19", "20-29", "30-39","40-49","50-59","60-69","70-80"))
# Observamos los datos discretizados.
head(ds)
# Vemos como se agrupan los datos.
plot(ds["segmento_edad"])
```

Se ha discretizado la variable "Age" en ocho intervalos de 10 años cada uno. Esta segmentación será de utilidad en apartados posteriores para analizar las relaciones de los datos. En el gráfico de barras representado se observa que, como ya habíamos obtenido la mayoría de los pasajeros se concentran en los segmentos "20-29" y "30-39".

__Fare__

Se va a realizar el mismo análisis para la variable Fare para tratar de determinar si hay valores extremos en esta variable. En primer lugar, aunque el atributo Ticket es algo inútil en cuanto a extraer información del propio número de ticket, proporciona información sobre cuántos tickets se compraron con una tarifa determinada, de modo que podamos calcular la tarifa por persona, que es lo que necesitamos ya que nuestra unidad de observación (una fila) es una persona. Creamos un atributo FarePerson y lo comparamos con el atributo Fare:

```{r,eval=TRUE,echo=TRUE}
# Cuenta de tickets
counts <- aggregate(ds$Ticket, by=list(ds$Ticket), 
                      FUN=function(ticket) sum(!is.na(ticket)))
# Función para el cálculo de ratio de tickets
compute_fare_person <- function(ds) {
  fare <- as.numeric(ds["Fare"])
  # Cuenta
  count_ticket_i <- counts[which(counts[,1] == ds["Ticket"]), 2]
  result <- round(fare/count_ticket_i,2)
  return(result)
}
# Aplicamos la función para obtener FarePerson
ds$FarePerson <- apply(X=ds, MARGIN=1, FUN=compute_fare_person)

```

A continuación, se representará el diagrama de cajas y bigotes y finalmente se analizarán los quartiles obtenidos y los posibles outliers.

```{r,eval=TRUE,echo=TRUE}
# Se representan los boxplot de la variable Fare
b2<-boxplot(ds$FarePerson, main="FarePerson")
b2$stats
length(b2$out)
```

Para la variable Age se obtiene que el valor del bigote inferior es 0 y el del bigote superior 47.10 dólares. Los extremos de la caja son 7.765 y 24.29 dólares, inferior y superior respectivamente, siendo la mediana del precio del ticket por pasajero 8.85 dólares. La interpretación de estos resultados indica que la mitad de los pasajeros a bordo del titanic pagó entre 7.765 y 24.29 dólares por el billete.
Además se ha obtenido que hay 59 puntos considerados outliers por situarse alejados del resto de datos, 1.5 veces mayor que el extremo de los bigotes. 
Para tratar estos valores extremos podrían aplicarse procedimientos como la eliminación de las filas con outliers o realizar imputación de estos valores como hicimos en el punto anterior. En este caso se va a realizar la discretización de la variable en grupos de precio, para reducir el ruido de la misma.

```{r,eval=TRUE,echo=TRUE}
# Discretizamos
ds["segmento_fare"] <- cut(ds$FarePerson, breaks = c(0,7.7,24.3,47.10,300), labels = c("Bajo", "Medio", "Elevado","Muy elevado"))

# Observamos los datos discretizados.
head(ds)
# Vemos como se agrupan los datos.
plot(ds["segmento_fare"])
```

Se ha discretizado la variable "FarePerson" en cuatro intervalos (Bajo, Medio, Elevado y Muy elevado) en función de los rangos intercuartílicos obtenidos en el gráfico de caja y bigotes. . Esta segmentación será de utilidad en apartados posteriores para analizar las relaciones de los datos. En el gráfico de barras representado se observa la distribución del número de billetes de cada categoría.

# 4. Análisis de los datos.

## 4.1. Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).

En este apartado se va a realizar un diseño del estudio estadístico que se quiere desarrollar. El objetivo último es definir si hay diferencias en la variable de clasificación "Survived", es decir en el resultado de supervivencia del pasajero, entre los diferentes grupos de pasajeros.

De las variables disponibles en el dataset se van a incluir en el estudio:
La variable __"Sex"__, categórica, para determinar si hay diferencias entre hombres y mujeres en la supervivencia. En el conjunto de entrenamiento hay un total de 314 mujeres y 577 hombres.

```{r,eval=TRUE,echo=TRUE}
table(ds$Sex)
# Representación
ggplot(ds, aes(x = Sex, fill = as.factor(Survived))) + theme_bw() + geom_bar(position="fill") + labs(y = "Passenger Count", title = "Titanic Survival by Sex")
```

Además, en el gráfico representado se observa que de las mujeres que viajaban en el barco hay un mayor porcentaje (75%) de supervivientes que entre los hombres.

La variable __"Age_segment"__, para determinar si hay diferencias entre los distintos rangos de edad en la supervivencia. En la tabla inferior se muestra el número de pasajeros que hay en cada grupo de edad, se observa que los grupos más numerosos son los correspondientes a los intervales "20-29" y "30-39" años.

```{r,eval=TRUE,echo=TRUE}
table(ds["segmento_edad"])
ggplot(ds, aes(x = segmento_edad, fill = as.factor(Survived))) + theme_bw() + geom_bar(position="fill") + labs(y = "Passenger Count", title = "Titanic Survival by Age Segment")
```

En el gráfico observamos que el segmento de edad con una mayor tasa de supervivencia es el de entre 0-9 años con aproximadamente un 60%. Los grupos con una menor tasa de supervivencia son los de los sujetos con una edad más avanzada. 

La variable __FarePerson__ para tratar de determinar si aquellos pasajeros que pagaron un ticket más caro tenían más posibilidades de supervivencia o a la inversa.La gran mayoría de los pasajeros compraron un billete con un precio medio.

```{r,eval=TRUE,echo=TRUE}
table(ds["segmento_fare"])
ggplot(ds, aes(x = segmento_fare, fill = as.factor(Survived))) + theme_bw() + geom_bar(position="fill") + labs(y = "Passenger Count", title = "Titanic Survival by Fare Segment")
```

En este nuevo gráfico obtenemos que la tasa de supervivencia aumenta en relación al precio pagado por el billete. De esta forma se observa que aquellos pasajeros que pagaron un precio muy elevado por los billetes tenían más posibilidades de sobrevivir (aprox. 70%) frente a menos del 25% de aquellos pasajeros que pagaron un precio bajo.

La variable __Pclass__ para determinar si hay diferentes en la superviviencia entre los pasajeros que viajaban en diferentes clases. Como se observa en la tabla inferior, el grupo más numeroso es el de pasajeros que viajaban en tercera clase.

```{r,eval=TRUE,echo=TRUE}
table(ds$Pclass)
# Representación
ggplot(ds, aes(x = Pclass, fill = as.factor(Survived))) + theme_bw() + geom_bar(position="fill") + labs(y = "Passenger Count", title = "Titanic Survival by Pclass")
```

Del gráfico se obtiene que hay un mayor porcentaje de supervivencia entre los pasajeros de primera clase (63%), así que parece que esta variable también tiene influencia en el resultado.

Finalmente se trabajará con la variable __nfamilares__, que representará el número de familiares que tenía cada pasajero a bordo del Titanic. Esta variable se obtendrá como suma de la variable "SibSp" y "Parch", de forma que no se diferenciará por el tipo de familiar si no por el número total de familiares. De esta forma se tratará de determinar si hay una mayor supervivencia en los pasajeros que tenían más (o menos) familiares a bordo.Como se observa en la tabla inferior, la mayoría de los pasajeros tenían 2 familiares a bordo, seguido de 3 y 4.

```{r,eval=TRUE,echo=TRUE}
ds$nfamiliares=as.numeric(ds$SibSp)+as.numeric(ds$Parch)
table(ds$nfamiliares)
# Representación
ggplot(ds, aes(x = nfamiliares, fill = as.factor(Survived))) + theme_bw() + geom_bar(position="fill") + labs(y = "Passenger Count", title = "Titanic Survival by Family Size")
```

En el gráfico superior se observa que la tasa de supervivencia aumenta con el número de familiares que tenía cada pasajero hasta llegar a 5 donde alcanza su máximo (70%). A partir de 5 familiares decrece esta tasa.

De esta forma, se concluye que las variables que se van a analizar en los siguientes apartados para estudiar su correlación con la supervivencia de los pasajeros son: "Sex", "Age_segment", "Fare_person","Pclass" y "nfamiliares".


## 4.2. Comprobación de la normalidad y homogeneidad de la varianza.

En primer lugar, se van a agrupar las variables que vamos a analizar en un nuevo dataset, en este caso en las variables continuas de las que disponemos en el dataset: Age y FarePerson. Vamos además a representar estas dos variables para analizar preliminarmente la distribución de estas variables a partir de un histograma.

```{r,eval=TRUE,echo=TRUE}
library(mltools)
library(data.table)
incluir <- c("Age","FarePerson")
newds <- ds[ , (names(ds) %in% incluir)]
ggplot(data=ds, aes(Age)) + geom_histogram(binwidth=5) + labs(title = "Age histogram")
ggplot(data=ds, aes(FarePerson)) + geom_histogram(binwidth=5) + labs(title = "FarePerson histogram")
```

En los gráficos obtenidos observamos que la variable Age sí que se aproxima más a una distribución normal, aunque no sucede lo mismo con la variable FarePerson. Vamos a realizar ahora las pruebas de normalidad aplicando el test Anderson-Darling. En este test la hipótesis nula H0 es que la muestra proviene de una distribución normal. Aplicaremos el test a las dos variables que hemos analizado previamente.

```{r,eval=TRUE,echo=TRUE}
library(nortest)
ad.test(newds$Age)
ad.test(newds$FarePerson)
```

Tanto para la variable Age como para la variable FarePerson se obtiene un pvalor menor que 2.2e-16. De esta forma ambos pvalores son menores que el nivel de significancia alfa (alfa=0.05). De esta forma no se puede rechazar la hipótesis nula para niguna de las variables y no podemos asumir que ninguna de ellas siga una distribución normal.

Vamos ahora a verificar si para estas variables podemos asumir la homogeneidad de la varianza para las clases que vamos a intentar predecir con el modelo (Survived). Para ello, se va a emplear la prueba de Fligner-Killeen que es una de las muchas pruebas de homogeneidad de varianzas y que es robusta frente a desviaciones de la normalidad. La hipótesis nula para este test es que la varianza de las poblaciones son iguales.

```{r,eval=TRUE,echo=TRUE}
fligner.test(Age ~ Survived, data = ds)
fligner.test(FarePerson ~ Survived, data = ds)
```

Puesto que obtenemos un p-valor inferior a 0,05, rechazamos la hipótesis de que las varianzas de ambas muestras son homogéneas.

## 4.3. Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.

Como el objetivo del estudio es predecir qué pasajeros sobrevivieron y cuáles no, el análisis de cada variable se hace en relación a la variable respuesta Survived. Analizando los datos de esta forma, se pueden empezar a extraer ideas sobre qué variables están más relacionadas con la supervivencia.

La distribución de la edad de los pasajeros parece ser muy similar entre el grupo de supervivientes y fallecidos, con dos excepciones: en el rango de edad aproximado de 0 a 10 años, el porcentaje de supervivencia es mucho mayor, mientras que, en el extremo opuesto, a partir de los 60 años, la tendencia se invierte. Dos hipótesis que podrían explicar estos patrones son: que, según los registros, en el protocolo de evacuación del Titanic se priorizó que mujeres y niños subiesen a los botes salvavidas, y que los ancianos tuviesen menor movilidad para alcanzar las zonas de evacuación.

```{r,eval=TRUE,echo=TRUE}
# Estadísticos de la edad de los supervivientes y fallecidos
ds %>% filter(!is.na(Age)) %>% group_by(Survived) %>%
  summarise(media = mean(Age),
            mediana = median(Age),
            min = min(Age),
            max = max(Age))
```
```{r,eval=TRUE,echo=TRUE}
library(ggpubr)
ggplot(data = ds, aes(x = segmento_edad, fill = Survived)) +
  geom_density(alpha = 0.5) +
  geom_rug(aes(color = Survived), alpha = 0.5) 
ggplot(data = ds, aes(x = Survived, y = segmento_edad, color = Survived)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(alpha = 0.3, width = 0.15) 
```

Podemos analizar la correlación existente entre variables contínuas.

```{r,eval=TRUE,echo=TRUE}
cor.test(x = ds$Age, y = ds$FarePerson, method = "pearson")
ggplot(data = ds, aes(x = Age, y = FarePerson)) +
  geom_point(color = "gray30") +
  geom_smooth(color = "firebrick") +
  theme_bw()
```

Como vemos, esta correlación no es significativa y por lo tanto podemos asumir que las variables no contienen información redundante.


Una de las preguntas que nos hemos planteado a lo largo de la práctica es si el coste del ticket tenía relación con la supervivencia del pasajero. Para ello vamos a realizar un scatterplot para dar respuesta a esta pregunta.

```{r,eval=TRUE,echo=TRUE}
plot(ds$FarePerson, ds$Survived, main="FarePerson vs Survived",
     xlab="FarePerson", ylab="Survived", pch=19)
```
Como podemos observar, no existe relación entre el coste y la supervivencia, ya que existen probabilidades similares de ambos resultados.

__Regresión logística__ 

Veamos ahora que tal se adapta un modelo de regresión logística a estos datos.

```{r,eval=TRUE,echo=TRUE}
incluir <- c("Survived","Sex","segmento_edad","FarePerson","Pclass","nfamiliares")
newds <- ds[ , (names(ds) %in% incluir)]

ds_test$Survived <- sample(0:1, 418, replace=TRUE)

ds_test$Pclass<-factor(ds_test$Pclass)
ds_test$Sex<-factor(ds_test$Sex)
ds_test$Parch<-factor(ds_test$Parch)
ds_test$SibSp<-factor(ds_test$SibSp)
ds_test["segmento_edad"] <- cut(ds_test$Age, breaks = c(0,10,20,30,40,50,60,70,100), labels = c("0-9", "10-19", "20-29", "30-39","40-49","50-59","60-69","70-80"))

# Cuenta de tickets
counts <- aggregate(ds_test$Ticket, by=list(ds_test$Ticket), 
                      FUN=function(ticket) sum(!is.na(ticket)))
# Aplicamos la función para obtener FarePerson
ds_test$FarePerson <- apply(X=ds_test, MARGIN=1, FUN=compute_fare_person)


ds_test$nfamiliares=as.numeric(ds_test$SibSp)+as.numeric(ds_test$Parch)
newds_test <- ds_test[ , (names(ds_test) %in% incluir)]


train <- newds
test <- newds_test

## Model Creation
model_glm <- glm(Survived ~.,family=binomial(link='logit'),data=train)

## Model Summary
summary(model_glm)

```

De los resultados del modelo observamos que todas las variables explicativas que hemos empleado son significativas a excepción de FarePerson y el segmento de edad entre 70-80 años. Por ello, vamos a probar a excluir esta variable y analizar el AIC del nuevo modelo para verificar si mejora el ajuste.

```{r,eval=TRUE,echo=TRUE}
model_glm2 <- glm(Survived ~Pclass+Sex+segmento_edad+nfamiliares,family=binomial(link='logit'),data=train)

## Model Summary
summary(model_glm2)
```

Observamos que con este nuevo modelo el AIC se ha reducido levemente por lo que hemos mejorado el ajuste del mismo y ahora todas las variables son significativas para el modelo.

```{r,eval=TRUE,echo=TRUE}
## Using anova() to analyze the table of devaiance
anova(model_glm2, test="Chisq")
```

```{r,eval=TRUE,echo=TRUE}
## Predicting Test Data
result <- predict(model_glm2,newdata=test,type='response')
result <- ifelse(result > 0.5,1,0)

result<-factor(result)
test$Survived<-factor(test$Survived)


## Confusion matrix and statistics
library(caret)
confusionMatrix(data=result, reference=test$Survived)

## ROC Curve and calculating the area under the curve(AUC)
library(ROCR)
predictions <- predict(model_glm2, newdata=test, type="response")
ROCRpred <- prediction(predictions, test$Survived)
ROCRperf <- performance(ROCRpred, measure = "tpr", x.measure = "fpr")

plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7), print.cutoffs.at = seq(0,1,0.1))

```
Como podemos observar, si usamos una regresión logística obtenemos un accuracy del 82% y observamos una buena evolución de la curva ROC.

Ahora vamos a comparar diferentes modelos contra la regresión logística que ya tenemos hecha utilizando cross validation. Para ello utilizaremos algoritmos lineales y no lineales:
  
  - Linear: Logistic Regression (LG) and Regularized Logistic Regression (GLMNET).
- Non-Linear: k-Nearest Neighbors (KNN), Classification and Regression Trees (CART), and Support Vector Machines with Radial Basis Functions (SVM).


```{r,eval=TRUE,echo=TRUE}

trainControl <- trainControl(method="repeatedcv", number=10, repeats=3)

# LG
set.seed(7)
fit.glm <- train(as.factor(Survived)~., data=train, method="glm", trControl=trainControl)
# GLMNET
set.seed(7)
fit.glmnet <- train(as.factor(Survived)~., data=train, method="glmnet", trControl=trainControl)
# KNN
set.seed(7)
fit.knn <- train(as.factor(Survived)~., data=train, method="knn",trControl=trainControl)
# CART
set.seed(7)
fit.cart <- train(as.factor(Survived)~., data=train, method="rpart", trControl=trainControl)
# SVM
set.seed(7)
fit.svm <- train(as.factor(Survived)~., data=train, method="svmRadial", trControl=trainControl)

# Compare algorithms
results <- resamples(list(LG=fit.glm, GLMNET=fit.glmnet, KNN=fit.knn,
                          CART=fit.cart, SVM=fit.svm))
summary(results)

```

Como podemos observar, SVM es el que nos da los mejores resultados con un Accuracy máximo del 92.5%, por lo que seguiremos trabajando con el en los próximos pasos, pero antes podemos probar de hacer un tuning y ver los resultados.

```{r,eval=TRUE,echo=TRUE}

trainControl <- trainControl(method="repeatedcv", number=10, repeats=3)
set.seed(7)
grid <- expand.grid(.sigma=c(0.025, 0.05, 0.1, 0.15), .C=seq(1, 10, by=1))
fit.svm <- train(as.factor(Survived)~., data=train, method="svmRadial",  tuneGrid=grid,
                 preProc=c("BoxCox"), trControl=trainControl)
print(fit.svm)
```

Esto nos devuelve que los valores óptimos son sigma = 0.025 y C = 5.

# 5. Representación de los resultados a partir de tablas y gráficas.

Repartimos los datos en train y test y vemos la distribución de supervivencia.

```{r,eval=TRUE,echo=TRUE}
library(caret)
set.seed(123)

datos_train <- newds
datos_test  <- newds_test

prop.table(table(datos_train$Survived))

```

Vemos que algo más del 61% de los datos de train, pertenece a Survived = 0, algo completamente normal sabiendo que la distribución del total de los datos ronda unos porcentajes similares.


```{r,eval=TRUE,echo=TRUE}
modelo_svm <- train(as.factor(Survived)~., method = "svmRadial", data = datos_train, tuneGrid=grid,preProc=c("BoxCox"), trControl=trainControl)
modelo_svm$finalModel
summary(modelo_svm$resample$Accuracy)
```
Después de aplicar SVM obtenemos una accuracy del 89,9% sobre los datos de train, un porcentaje bastante correcto que nos anima a utilizar este modelo para valorar los resultados.

```{r,eval=TRUE,echo=TRUE}
## Predicting Test Data
result <- predict(modelo_svm,newdata=datos_test,type='raw')

result<-factor(result)
result


```
Otra estrategía que podríamos considerar es la de usar un árbol de clasificación con tal de encontrar los patrones que nos lleven a saber si un pasajero sobrevivió o no al accidente.


```{r,eval=TRUE,echo=TRUE}
library(rpart)
my_tree<-rpart(Survived ~ Sex + segmento_edad + FarePerson + Pclass + nfamiliares, data = datos_train, method = "class")
#plot(my_tree)
#text(my_tree)


#library(rattle) I had lot of trouble installing this... I get this working in the console but when i do knit it gives me problem..So commented it out..

library(rpart.plot)
library(RColorBrewer)
new.fit <- prp(my_tree,snip=TRUE)$obj
```

# 6. Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?

La exploración de los datos, el estudio de su distribución, y su posible relación con la variable respuesta parecen indicar que los factores que más influyeron en la supervivencia de los pasajeros fueron: el sexo, la clase a la que pertenecían y, en menor medida, si tenían o no al menos un hijo a bordo. También se ha detectado que las variables continuas no están correlacionadas y que las variables Age, Cabin y Embarked tienen valores ausentes. Aún así podemos observar que hay muchos predictores que afectan a que un pasajero sobreviva o no al accidente.

Podemos decir que es mas probable que las mujeres y los niños tenían más probabilidad de sobrevivir que los hombres, algo que refuerza la teoría de mujeres y niños primero y que las personas mayores tienen un índice de supervivencia más bajo, como hemos comentado antes, que podría ser debido a que por movilidad reducida fueran incapaces de llegar a una salida.

También podemos observar que las personas con una clase más baja tienen menos probabilidades de sobrevivir, mientras que con el resto de variables resultan más dificil sacar conclusiones.

Como propuesta de mejora, se podría llegar a analizar los parentescos reforzando el análisis de la familia a partir de los apellidos, algo que podría darnos más información sobre familias que sobrevivieron.

Finalmente, a partir de los resultados obtenidos, podríamos llegar a predecir con un buen margen de acierto si un pasajero sobrevivió o no al accidente basandonos en el modelo entrenado en esta práctica.
